```
multiprocessing is best to handle CPU-bound tasks
```
## 01. use multiprocessing

```
import multiprocessing

def process_task(name):
    print(f"Task {name} is running")

if __name__ == "__main__":
    task = 10
    i = 0
    max_worker = 5
    process_gather = []

    while i < task:
        for j in range(max_worker):
            if i < task:
                process = multiprocessing.Process(target=process_task, args=(i,))
                process_gather.append(process)
                process.start()  # Starts the process
                i += 1
            else:
                print('All Tasks Appended')
                break

    for process in process_gather:
        process.join()  # Wait for all processes to complete

```
## 02. Using concurrent.futures submit
```
Submit append task work randomly
```
```py
import concurrent.futures
import time

def io_task(name, duration):
    print(f"Starting task {name}")
    time.sleep(duration)  # Simulating an I/O-bound task
    print(f"Finished task {name}")
    return name, duration

max_worker = 5
task = 10
with concurrent.futures.ProcessPoolExecutor(max_workers=max_worker) as executor:
    i = 0
    thread_gather = []
    while i < task:
       for i in range(max_worker):
            if i < task:
                thread_gather.append(executor.submit(io_task, 'task name',5))   # first arg func name, next arguments of func
            else:
                print('All Task Appended')

       # Retrieve and print results
       for future in concurrent.futures.as_completed(futures):
            try:
                result = future.result()
                print(f"Result: {result}")
            except Exception as ops:
                print(f"Error: {ops}")
```
## 03. Using concurrent.futures map()
```
Same order return of input order
```
```py
import concurrent.futures
import time

def io_task(name, duration):
    print(f"Starting task {name}")
    time.sleep(duration)  # Simulating an I/O-bound task
    print(f"Finished task {name}")
    return name, duration

max_worker = 5
task = 10

with concurrent.futures.ProcessPoolExecutor(max_workers=max_worker) as executor:
    i = 0
    tasks = []
    
    # Create tasks just like before
    while i < task:
        for i in range(max_worker):
            if i < task:
                tasks.append(('task name', 5))  # Appending tuple with task name and duration
            else:
                print('All Task Appended')

        # Instead of using list comprehensions, directly pass the tasks list using unpacking with *
        results = executor.map(lambda t: io_task(*t), tasks)  # Use a lambda to unpack each tuple in tasks
    
        # Print results
        for result in results:
            print(f"Result: {result}")
```
## 04. Using threading & processing
```py
import concurrent.futures

def io_bound_task(name):
    print(f"IO-bound task {name}")
    return f"Finished IO {name}"

def cpu_bound_task(n):
    print(f"CPU-bound task {n}")
    return n ** 2

# Running both Thread and Process pools
with concurrent.futures.ThreadPoolExecutor(max_workers=3) as thread_executor, \
     concurrent.futures.ProcessPoolExecutor(max_workers=3) as process_executor:

    # Submitting I/O-bound tasks to ThreadPool
    io_futures = [thread_executor.submit(io_bound_task, i) for i in range(3)]

    # Submitting CPU-bound tasks to ProcessPool
    cpu_futures = [process_executor.submit(cpu_bound_task, i) for i in range(3)]

    # Handling both results
    for future in concurrent.futures.as_completed(io_futures + cpu_futures):
        result = future.result()
        print(f"Result: {result}")
```
## 05. multiprocessing Virtual Space concept
```py
from time import sleep
import multiprocessing

square = []  ## In main thread
## In virtual thread
def fun1(number):
    global square  # Global should work, out of function area, without return it should work,
                    # but it won't work cause process take virtual space where, memory is different
    for num in number:
        square.append(num*num)
        sleep(0.2)
        print('Fun 1 : ', num)
    print('square data in Process : ', square)

# Multi Processing
if __name__ == '__main__':
    lst = [1, 2, 3, 4, 5]
    p1 = multiprocessing.Process(target=fun1, args=(lst,))
    p1.start()
    p1.join()
    print('square data out of Process : ', square)

```

