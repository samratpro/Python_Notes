```
threading is best to handle I/O-bound tasks
```

## 01. Using threading
```py
import threading

def thread_task(name):
    print(f"Task {name} is running")

task = 10
i = 0
max_worker = 5
thread_gather = []
while i < task
    for j in range(max_worker):
        if i < task:            
            thread = threading.Thread(target=thread_task, args=('name',))
            thread_gather.append(thread)
            thread_gather.start()
        else:
            print('All Task Appended')
            
for thread in thread_gather:
    thread.join()
```
## 02. Using concurrent.futures Sunmit
```
Submit append task work randomly
```
```py
import concurrent.futures
import time

def io_task(name, duration):
    print(f"Starting task {name}")
    time.sleep(duration)  # Simulating an I/O-bound task
    print(f"Finished task {name}")
    return name, duration

max_worker = 5
task = 10
with concurrent.futures.ThreadPoolExecutor(max_workers=max_worker) as executor:
    i = 0
    thread_gather = []
    while i < task:
       for i in range(max_worker):
            if i < task:
                thread_gather.append(executor.submit(io_task, 'task name',5))   # first arg func name, next arguments of func
            else:
                print('All Task Appended')

       # Retrieve and print results
       for future in concurrent.futures.as_completed(futures):
            try:
                result = future.result()
                print(f"Result: {result}")
            except Exception as ops:
                print(f"Error: {ops}")
```
## 03. concurrent.futures map
```
Same order return of input order
```
```py
import concurrent.futures
import time

def io_task(name, duration):
    print(f"Starting task {name}")
    time.sleep(duration)  # Simulating an I/O-bound task
    print(f"Finished task {name}")
    return name, duration

max_worker = 5
task = 10

with concurrent.futures.ThreadPoolExecutor(max_workers=max_worker) as executor:
    i = 0
    tasks = []
    
    # Create tasks just like before
    while i < task:
        for i in range(max_worker):
            if i < task:
                tasks.append(('task name', 5))  # Appending tuple with task name and duration
            else:
                print('All Task Appended')

        # Instead of using list comprehensions, directly pass the tasks list using unpacking with *
        results = executor.map(lambda t: io_task(*t), tasks)  # Use a lambda to unpack each tuple in tasks
    
        # Print results
        for result in results:
            print(f"Result: {result}")
```
## 04. Using threading & processing
```py
import concurrent.futures

def io_bound_task(name):
    print(f"IO-bound task {name}")
    return f"Finished IO {name}"

def cpu_bound_task(n):
    print(f"CPU-bound task {n}")
    return n ** 2

# Running both Thread and Process pools
with concurrent.futures.ThreadPoolExecutor(max_workers=3) as thread_executor, \
     concurrent.futures.ProcessPoolExecutor(max_workers=3) as process_executor:

    # Submitting I/O-bound tasks to ThreadPool
    io_futures = [thread_executor.submit(io_bound_task, i) for i in range(3)]

    # Submitting CPU-bound tasks to ProcessPool
    cpu_futures = [process_executor.submit(cpu_bound_task, i) for i in range(3)]

    # Handling both results
    for future in concurrent.futures.as_completed(io_futures + cpu_futures):
        result = future.result()
        print(f"Result: {result}")
```
