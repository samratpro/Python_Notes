### Install
```bash
pip install scrapy
```
### Start Project
```
scrapy startproject projectname
cd projectname
scrapy genspider domain_name domain.com   # domain name is optional
```
### spider/domain_name.py
A ready template will have there just need to start from parse
```py
import scrapy
from projectname.items import ProjectnameItem

class domain_nameSpider(scrapy.Spider):
    name = "domain_name"
    start_urls = ["http://domain.com/home/en/events/"]  # insert start url

    def parse(self, response):
        item = ScrapdataItem()
        item["title"] = response.css("h1::text").get()
        item["link"] = response.url
        item["description"] = response.css("p::text").getall()
        yield item
```
### items.py
```py
import scrapy
class ScrapdataItem(scrapy.Item):
    title = scrapy.Field()
    link = scrapy.Field()
    description = scrapy.Field()
```
### Run
```py
scrapy crawl domain_name -o domain_name.json
scrapy crawl domain_name -o domain_name.csv
```


