### Install
```bash
pip install scrapy
```
### Start Project
```
scrapy startproject projectname
cd projectname
scrapy genspider domain_name domain.com   # domain name is optional
```
### spider/domain_name.py
A ready template will have there just need to start from parse
```py
import scrapy
from projectname.items import ProjectnameItem

class domain_nameSpider(scrapy.Spider):
    name = "domain_name"
    start_urls = ["http://domain.com/home/en/events/"]  # insert start url

    def parse(self, response):
        item = ScrapdataItem()
        item["title"] = response.css("h1::text").get()
        item["link"] = response.url
        item["description"] = response.css("p::text").getall()
        yield item
```
### items.py
```py
import scrapy
class ScrapdataItem(scrapy.Item):
    title = scrapy.Field()
    link = scrapy.Field()
    description = scrapy.Field()
```
### Run
```py
scrapy crawl domain_name -o domain_name.json
scrapy crawl domain_name -o domain_name.csv
```

### One Spider for Multiple Domains
```py
# myproject/spiders/multisite.py
import scrapy
class MultiSiteSpider(scrapy.Spider):
    name = 'multisite'
    start_urls = [
        'https://site1.com/page',
        'https://site2.org/page',
    ]

    def parse(self, response):
        domain = response.url.split("/")[2]
        if "site1.com" in domain:
            yield from self.parse_site1(response)
        elif "site2.org" in domain:
            yield from self.parse_site2(response)
```
### One Spider Per Domain
```bash
scrapy genspider site1_spider site1.com
scrapy genspider site2_spider site2.org
```
```
spiders/
  └── site1_spider.py
  └── site2_spider.py
```



